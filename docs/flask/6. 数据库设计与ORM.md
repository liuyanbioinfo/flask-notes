# ğŸ—„ï¸ 6. æ•°æ®åº“è®¾è®¡ä¸ ORM

æ•°æ®åº“æ˜¯Webåº”ç”¨çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£æ•°æ®çš„æŒä¹…åŒ–å­˜å‚¨å’Œç®¡ç†ã€‚æœ¬ç« å°†æ·±å…¥æ¢è®¨Flaskä¸­çš„æ•°æ®åº“è®¾è®¡åŸåˆ™ã€ORMä½¿ç”¨æŠ€å·§ä»¥åŠæ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼Œå¸®åŠ©ä½ æ„å»ºé«˜æ•ˆã€å¯æ‰©å±•çš„æ•°æ®å±‚æ¶æ„ã€‚

## ğŸ¯ 6.1 æ•°æ®åº“é€‰æ‹©ä¸è®¾è®¡åŸåˆ™

### æ•°æ®åº“æŠ€æœ¯é€‰å‹

```mermaid
mindmap
  root((ğŸ—„ï¸ æ•°æ®åº“é€‰å‹))
    ğŸ“Š å…³ç³»å‹æ•°æ®åº“
      SQLite
        è½»é‡çº§
        é›¶é…ç½®
        æ–‡ä»¶å­˜å‚¨
      MySQL
        æˆç†Ÿç¨³å®š
        é«˜æ€§èƒ½
        å¹¿æ³›æ”¯æŒ
      PostgreSQL
        åŠŸèƒ½ä¸°å¯Œ
        æ ‡å‡†å…¼å®¹
        é«˜æ‰©å±•æ€§
    ğŸ”„ NoSQLæ•°æ®åº“
      MongoDB
        æ–‡æ¡£å­˜å‚¨
        çµæ´»æ¨¡å¼
        æ°´å¹³æ‰©å±•
      Redis
        å†…å­˜å­˜å‚¨
        é«˜æ€§èƒ½
        ç¼“å­˜ä¼˜åŒ–
```

### ğŸ—ï¸ æ•°æ®åº“è®¾è®¡åŸåˆ™

**1. è§„èŒƒåŒ–è®¾è®¡**

```mermaid
flowchart TD
    A[åŸå§‹æ•°æ®è¡¨] --> B[ç¬¬ä¸€èŒƒå¼ 1NF]
    B --> C[ç¬¬äºŒèŒƒå¼ 2NF]
    C --> D[ç¬¬ä¸‰èŒƒå¼ 3NF]
    D --> E[BCNFèŒƒå¼]
    
    B1[æ¶ˆé™¤é‡å¤ç»„] --> B
    C1[æ¶ˆé™¤éƒ¨åˆ†ä¾èµ–] --> C
    D1[æ¶ˆé™¤ä¼ é€’ä¾èµ–] --> D
    E1[æ¶ˆé™¤ä¸»å±æ€§ä¾èµ–] --> E
```

**2. æ€§èƒ½ä¼˜åŒ–è®¾è®¡**

```python
# ğŸ¯ ç´¢å¼•ç­–ç•¥è®¾è®¡
class User(db.Model):
    __tablename__ = 'users'
    
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(80), unique=True, nullable=False, index=True)
    email = db.Column(db.String(120), unique=True, nullable=False, index=True)
    created_at = db.Column(db.DateTime, default=datetime.utcnow, index=True)
    
    # å¤åˆç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
    __table_args__ = (
        db.Index('ix_user_status_created', 'is_active', 'created_at'),
        db.Index('ix_user_email_domain', 'email'),  # æ”¯æŒé‚®ç®±åŸŸåæŸ¥è¯¢
    )

# ğŸ” åˆ†åŒºè¡¨è®¾è®¡ï¼ˆå¤§æ•°æ®é‡åœºæ™¯ï¼‰
class UserActivity(db.Model):
    __tablename__ = 'user_activities'
    
    id = db.Column(db.Integer, primary_key=True)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    activity_type = db.Column(db.String(50), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)
    
    # æŒ‰æ—¶é—´åˆ†åŒºçš„ç´¢å¼•ç­–ç•¥
    __table_args__ = (
        db.Index('ix_activity_user_time', 'user_id', 'created_at'),
        db.Index('ix_activity_type_time', 'activity_type', 'created_at'),
    )
```

### ğŸ“‹ æ•°æ®åº“é€‰æ‹©å¯¹æ¯”

| ç‰¹æ€§ | SQLite | MySQL | PostgreSQL | MongoDB | Redis |
|------|--------|-------|------------|---------|-------|
| ğŸ¯ **é€‚ç”¨åœºæ™¯** | åŸå‹å¼€å‘ | Webåº”ç”¨ | ä¼ä¸šçº§åº”ç”¨ | æ–‡æ¡£å­˜å‚¨ | ç¼“å­˜/ä¼šè¯ |
| âš¡ **æ€§èƒ½** | ä¸­ç­‰ | é«˜ | é«˜ | é«˜ | æé«˜ |
| ğŸ”§ **é…ç½®å¤æ‚åº¦** | æä½ | ä¸­ç­‰ | ä¸­é«˜ | ä¸­ç­‰ | ä½ |
| ğŸ“ˆ **æ‰©å±•æ€§** | ä½ | ä¸­é«˜ | é«˜ | æé«˜ | ä¸­ç­‰ |
| ğŸ’° **æˆæœ¬** | å…è´¹ | å…è´¹/ä»˜è´¹ | å…è´¹ | å…è´¹/ä»˜è´¹ | å…è´¹/ä»˜è´¹ |

## âš™ï¸ 6.2 SQLAlchemy æ ¸å¿ƒæ¦‚å¿µ

### ORMæ¶æ„åŸç†

```mermaid
flowchart TB
    subgraph "åº”ç”¨å±‚"
        A[Pythonå¯¹è±¡] --> B[SQLAlchemy ORM]
    end
    
    subgraph "æŠ½è±¡å±‚"
        B --> C[SQLAlchemy Core]
        C --> D[æ•°æ®åº“æ–¹è¨€]
    end
    
    subgraph "æ•°æ®åº“å±‚"
        D --> E[SQLite]
        D --> F[MySQL]
        D --> G[PostgreSQL]
    end
    
    H[æŸ¥è¯¢æ„å»ºå™¨] --> C
    I[è¿æ¥æ± ] --> C
    J[äº‹åŠ¡ç®¡ç†] --> C
```

### ğŸ­ é«˜çº§é…ç½®ä¸ä¼˜åŒ–

```python
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

class DatabaseConfig:
    """æ•°æ®åº“é…ç½®ç±»"""
    
    @staticmethod
    def get_database_uri(env='development'):
        """æ ¹æ®ç¯å¢ƒè·å–æ•°æ®åº“URI"""
        configs = {
            'development': 'sqlite:///dev.db',
            'testing': 'sqlite:///:memory:',
            'production': os.environ.get('DATABASE_URL')
        }
        return configs.get(env, configs['development'])
    
    @staticmethod
    def get_engine_options():
        """è·å–æ•°æ®åº“å¼•æ“é…ç½®"""
        return {
            'poolclass': QueuePool,
            'pool_size': 10,          # è¿æ¥æ± å¤§å°
            'max_overflow': 20,       # æœ€å¤§æº¢å‡ºè¿æ¥
            'pool_timeout': 30,       # è¿æ¥è¶…æ—¶æ—¶é—´
            'pool_recycle': 3600,     # è¿æ¥å›æ”¶æ—¶é—´
            'echo': False,            # ç”Ÿäº§ç¯å¢ƒå…³é—­SQLæ—¥å¿—
        }

# ğŸ”§ Flaskåº”ç”¨é…ç½®
def create_app(config_name='development'):
    app = Flask(__name__)
    
    # æ•°æ®åº“é…ç½®
    app.config['SQLALCHEMY_DATABASE_URI'] = DatabaseConfig.get_database_uri(config_name)
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    app.config['SQLALCHEMY_ENGINE_OPTIONS'] = DatabaseConfig.get_engine_options()
    
    # åˆå§‹åŒ–æ‰©å±•
    db.init_app(app)
    
    return app
```

### ğŸ¨ ä¼šè¯ç®¡ç†ä¸ä¸Šä¸‹æ–‡

```python
from contextlib import contextmanager

@contextmanager
def db_transaction():
    """æ•°æ®åº“äº‹åŠ¡ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    try:
        db.session.begin()
        yield db.session
        db.session.commit()
    except Exception as e:
        db.session.rollback()
        raise e
    finally:
        db.session.close()

# ä½¿ç”¨äº‹åŠ¡ä¸Šä¸‹æ–‡
def transfer_points(from_user_id, to_user_id, points):
    """ç§¯åˆ†è½¬è´¦ç¤ºä¾‹"""
    with db_transaction() as session:
        from_user = session.query(User).get(from_user_id)
        to_user = session.query(User).get(to_user_id)
        
        if from_user.points < points:
            raise ValueError('ç§¯åˆ†ä¸è¶³')
        
        from_user.points -= points
        to_user.points += points
        
        # è®°å½•è½¬è´¦æ—¥å¿—
        transfer_log = PointsTransfer(
            from_user_id=from_user_id,
            to_user_id=to_user_id,
            points=points
        )
        session.add(transfer_log)
```

## ğŸ—ï¸ 6.3 æ¨¡å‹è®¾è®¡ä¸å…³ç³»æ˜ å°„

### å¤æ‚å…³ç³»æ¨¡å‹è®¾è®¡

```python
from sqlalchemy.ext.hybrid import hybrid_property
from sqlalchemy import func, select

class User(db.Model):
    """ğŸ‘¤ ç”¨æˆ·æ¨¡å‹ - æ ¸å¿ƒå®ä½“"""
    __tablename__ = 'users'
    
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(80), unique=True, nullable=False)
    email = db.Column(db.String(120), unique=True, nullable=False)
    password_hash = db.Column(db.String(255), nullable=False)
    
    # ğŸ“Š ç”¨æˆ·ç»Ÿè®¡å­—æ®µ
    posts_count = db.Column(db.Integer, default=0)
    followers_count = db.Column(db.Integer, default=0)
    following_count = db.Column(db.Integer, default=0)
    
    # ğŸ•’ æ—¶é—´æˆ³
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    last_login = db.Column(db.DateTime)
    
    # ğŸ”— å…³ç³»æ˜ å°„
    posts = db.relationship('Post', backref='author', lazy='dynamic', cascade='all, delete-orphan')
    profile = db.relationship('UserProfile', backref='user', uselist=False, cascade='all, delete-orphan')
    
    # ğŸ‘¥ å¤šå¯¹å¤šå…³ç³»ï¼šå…³æ³¨ç³»ç»Ÿ
    following = db.relationship(
        'User', 
        secondary='user_follows',
        primaryjoin='User.id == user_follows.c.follower_id',
        secondaryjoin='User.id == user_follows.c.followed_id',
        backref=db.backref('followers', lazy='dynamic'),
        lazy='dynamic'
    )
    
    @hybrid_property
    def is_active_user(self):
        """æ´»è·ƒç”¨æˆ·åˆ¤æ–­"""
        return self.posts_count > 0 and self.last_login > datetime.utcnow() - timedelta(days=30)
    
    @is_active_user.expression
    def is_active_user(cls):
        return (cls.posts_count > 0) & (cls.last_login > datetime.utcnow() - timedelta(days=30))
    
    def follow(self, user):
        """å…³æ³¨ç”¨æˆ·"""
        if not self.is_following(user):
            self.following.append(user)
            self.following_count += 1
            user.followers_count += 1
    
    def unfollow(self, user):
        """å–æ¶ˆå…³æ³¨"""
        if self.is_following(user):
            self.following.remove(user)
            self.following_count -= 1
            user.followers_count -= 1
    
    def is_following(self, user):
        """æ£€æŸ¥æ˜¯å¦å·²å…³æ³¨"""
        return self.following.filter(user_follows.c.followed_id == user.id).count() > 0

# ğŸ‘¥ å…³æ³¨å…³ç³»è¡¨
user_follows = db.Table('user_follows',
    db.Column('follower_id', db.Integer, db.ForeignKey('users.id'), primary_key=True),
    db.Column('followed_id', db.Integer, db.ForeignKey('users.id'), primary_key=True),
    db.Column('created_at', db.DateTime, default=datetime.utcnow)
)

class Post(db.Model):
    """ğŸ“ æ–‡ç« æ¨¡å‹"""
    __tablename__ = 'posts'
    
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(200), nullable=False)
    slug = db.Column(db.String(200), unique=True, nullable=False)
    content = db.Column(db.Text, nullable=False)
    summary = db.Column(db.String(500))
    
    # ğŸ“Š ç»Ÿè®¡å­—æ®µ
    views_count = db.Column(db.Integer, default=0)
    likes_count = db.Column(db.Integer, default=0)
    comments_count = db.Column(db.Integer, default=0)
    
    # ğŸ·ï¸ åˆ†ç±»å’ŒçŠ¶æ€
    status = db.Column(db.Enum('draft', 'published', 'archived', name='post_status'), default='draft')
    is_featured = db.Column(db.Boolean, default=False)
    
    # ğŸ•’ æ—¶é—´æˆ³
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    published_at = db.Column(db.DateTime)
    
    # ğŸ”— å¤–é”®å…³ç³»
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    category_id = db.Column(db.Integer, db.ForeignKey('categories.id'))
    
    # ğŸ·ï¸ å¤šå¯¹å¤šå…³ç³»ï¼šæ ‡ç­¾
    tags = db.relationship('Tag', secondary='post_tags', backref=db.backref('posts', lazy='dynamic'))
    
    # ğŸ’¬ ä¸€å¯¹å¤šå…³ç³»ï¼šè¯„è®º
    comments = db.relationship('Comment', backref='post', lazy='dynamic', cascade='all, delete-orphan')
    
    @hybrid_property
    def reading_time(self):
        """é¢„ä¼°é˜…è¯»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        words_per_minute = 200
        word_count = len(self.content.split())
        return max(1, word_count // words_per_minute)
    
    def publish(self):
        """å‘å¸ƒæ–‡ç« """
        self.status = 'published'
        self.published_at = datetime.utcnow()
        self.author.posts_count += 1
```

### ğŸ¯ å…³ç³»æ˜ å°„å¯è§†åŒ–

```mermaid
erDiagram
    USER ||--o{ POST : "åˆ›ä½œ"
    USER ||--|| USER_PROFILE : "æ‹¥æœ‰"
    USER }o--o{ USER : "å…³æ³¨å…³ç³»"
    POST }o--|| CATEGORY : "åˆ†ç±»"
    POST }o--o{ TAG : "æ ‡ç­¾"
    POST ||--o{ COMMENT : "è¯„è®º"
    USER ||--o{ COMMENT : "å‘è¡¨"
    
    USER {
        int id PK
        string username UK
        string email UK
        string password_hash
        int posts_count
        int followers_count
        int following_count
        datetime created_at
        datetime last_login
    }
    
    POST {
        int id PK
        string title
        string slug UK
        text content
        string summary
        int views_count
        int likes_count
        enum status
        boolean is_featured
        datetime created_at
        datetime updated_at
        datetime published_at
        int user_id FK
        int category_id FK
    }
    
    USER_PROFILE {
        int id PK
        string full_name
        text bio
        string avatar_url
        string website
        json social_links
        int user_id FK
    }
    
    CATEGORY {
        int id PK
        string name UK
        string slug UK
        text description
        int posts_count
    }
    
    TAG {
        int id PK
        string name UK
        string color
        int usage_count
    }
    
    COMMENT {
        int id PK
        text content
        datetime created_at
        int user_id FK
        int post_id FK
        int parent_id FK
    }
```

## ğŸš€ 6.4 æŸ¥è¯¢ä¼˜åŒ–ä¸æ€§èƒ½è°ƒä¼˜

### æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥

```python
from sqlalchemy.orm import joinedload, selectinload, subqueryload
from sqlalchemy import func, and_, or_

class PostService:
    """ğŸ“ æ–‡ç« æœåŠ¡ç±» - å°è£…å¤æ‚æŸ¥è¯¢é€»è¾‘"""
    
    @staticmethod
    def get_featured_posts_with_authors(limit=10):
        """ğŸŒŸ è·å–ç²¾é€‰æ–‡ç« ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        return (Post.query
                .options(joinedload(Post.author))  # é¢„åŠ è½½ä½œè€…ä¿¡æ¯ï¼Œé¿å…N+1æŸ¥è¯¢
                .filter(Post.is_featured == True, Post.status == 'published')
                .order_by(Post.created_at.desc())
                .limit(limit)
                .all())
    
    @staticmethod
    def get_posts_with_stats():
        """ğŸ“Š è·å–æ–‡ç« ç»Ÿè®¡ä¿¡æ¯"""
        return (db.session.query(
                    Post.id,
                    Post.title,
                    Post.views_count,
                    User.username.label('author_name'),
                    func.count(Comment.id).label('comments_count')
                )
                .join(User)
                .outerjoin(Comment)
                .group_by(Post.id, User.username)
                .order_by(Post.views_count.desc())
                .all())
    
    @staticmethod
    def search_posts(keyword, category_id=None, tag_names=None):
        """ğŸ” å¤åˆæ¡ä»¶æœç´¢"""
        query = (Post.query
                .options(joinedload(Post.author), selectinload(Post.tags))
                .filter(Post.status == 'published'))
        
        # å…³é”®è¯æœç´¢
        if keyword:
            search_filter = or_(
                Post.title.contains(keyword),
                Post.content.contains(keyword)
            )
            query = query.filter(search_filter)
        
        # åˆ†ç±»ç­›é€‰
        if category_id:
            query = query.filter(Post.category_id == category_id)
        
        # æ ‡ç­¾ç­›é€‰
        if tag_names:
            query = query.join(Post.tags).filter(Tag.name.in_(tag_names))
        
        return query.order_by(Post.created_at.desc())
    
    @staticmethod
    def get_user_timeline(user_id, page=1, per_page=20):
        """ğŸ“± ç”¨æˆ·æ—¶é—´çº¿ï¼ˆå…³æ³¨ç”¨æˆ·çš„æ–‡ç« ï¼‰"""
        followed_users = (db.session.query(user_follows.c.followed_id)
                         .filter(user_follows.c.follower_id == user_id)
                         .subquery())
        
        return (Post.query
                .options(joinedload(Post.author))
                .filter(Post.user_id.in_(followed_users))
                .filter(Post.status == 'published')
                .order_by(Post.created_at.desc())
                .paginate(page=page, per_page=per_page, error_out=False))

# ğŸ¯ æŸ¥è¯¢æ€§èƒ½ç›‘æ§è£…é¥°å™¨
import time
from functools import wraps

def monitor_query_performance(func):
    """æŸ¥è¯¢æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        execution_time = time.time() - start_time
        
        if execution_time > 1.0:  # è¶…è¿‡1ç§’çš„æ…¢æŸ¥è¯¢
            app.logger.warning(f'æ…¢æŸ¥è¯¢æ£€æµ‹: {func.__name__} è€—æ—¶ {execution_time:.2f}s')
        
        return result
    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
@monitor_query_performance
def get_popular_posts():
    return PostService.get_posts_with_stats()
```

### ğŸ”§ æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–

```python
class OptimizedModels:
    """ä¼˜åŒ–åçš„æ¨¡å‹è®¾è®¡"""
    
    class Post(db.Model):
        __tablename__ = 'posts'
        
        # ... å­—æ®µå®šä¹‰ ...
        
        # ğŸ¯ å¤åˆç´¢å¼•ç­–ç•¥
        __table_args__ = (
            # çŠ¶æ€ + åˆ›å»ºæ—¶é—´ç´¢å¼•ï¼ˆç”¨äºæ–‡ç« åˆ—è¡¨æŸ¥è¯¢ï¼‰
            db.Index('ix_post_status_created', 'status', 'created_at'),
            
            # ä½œè€… + çŠ¶æ€ç´¢å¼•ï¼ˆç”¨äºç”¨æˆ·æ–‡ç« æŸ¥è¯¢ï¼‰
            db.Index('ix_post_user_status', 'user_id', 'status'),
            
            # åˆ†ç±» + çŠ¶æ€ + åˆ›å»ºæ—¶é—´ç´¢å¼•
            db.Index('ix_post_category_status_created', 'category_id', 'status', 'created_at'),
            
            # ç²¾é€‰æ–‡ç« ç´¢å¼•
            db.Index('ix_post_featured_status', 'is_featured', 'status'),
            
            # å…¨æ–‡æœç´¢ç´¢å¼•ï¼ˆMySQLï¼‰
            # db.Index('ix_post_fulltext', 'title', 'content', mysql_prefix='FULLTEXT'),
        )

# ğŸ“Š æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’åˆ†æ
def analyze_query_performance():
    """åˆ†ææŸ¥è¯¢æ€§èƒ½"""
    from sqlalchemy import text
    
    # è·å–æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’
    query = text("""
        EXPLAIN QUERY PLAN 
        SELECT p.*, u.username 
        FROM posts p 
        JOIN users u ON p.user_id = u.id 
        WHERE p.status = 'published' 
        ORDER BY p.created_at DESC 
        LIMIT 10
    """)
    
    result = db.session.execute(query)
    for row in result:
        print(row)
```

## ğŸ”„ 6.5 æ•°æ®åº“è¿ç§»ç­–ç•¥

### è¿ç§»æœ€ä½³å®è·µ

```python
# ğŸ“‹ è¿ç§»è„šæœ¬æ¨¡æ¿
"""æ·»åŠ ç”¨æˆ·ç§¯åˆ†ç³»ç»Ÿ

Revision ID: abc123def456
Revises: previous_revision
Create Date: 2024-01-15 10:30:00.000000
"""

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import mysql, postgresql

def upgrade():
    """å‡çº§æ•°æ®åº“ç»“æ„"""
    # ğŸ†• æ·»åŠ æ–°è¡¨
    op.create_table('user_points',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('points', sa.Integer(), default=0),
        sa.Column('total_earned', sa.Integer(), default=0),
        sa.Column('total_spent', sa.Integer(), default=0),
        sa.Column('created_at', sa.DateTime(), nullable=True),
        sa.Column('updated_at', sa.DateTime(), nullable=True),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('user_id')
    )
    
    # ğŸ“Š æ·»åŠ ç´¢å¼•
    op.create_index('ix_user_points_user_id', 'user_points', ['user_id'])
    op.create_index('ix_user_points_points', 'user_points', ['points'])
    
    # ğŸ”„ æ•°æ®è¿ç§»ï¼šä¸ºç°æœ‰ç”¨æˆ·åˆ›å»ºç§¯åˆ†è®°å½•
    connection = op.get_bind()
    connection.execute(
        sa.text("""
            INSERT INTO user_points (user_id, points, created_at, updated_at)
            SELECT id, 0, created_at, created_at FROM users
        """)
    )
    
    # âš¡ æ·»åŠ è§¦å‘å™¨ï¼ˆMySQLç¤ºä¾‹ï¼‰
    if connection.dialect.name == 'mysql':
        connection.execute(sa.text("""
            CREATE TRIGGER update_user_points_timestamp
            BEFORE UPDATE ON user_points
            FOR EACH ROW
            SET NEW.updated_at = NOW()
        """))

def downgrade():
    """å›æ»šæ•°æ®åº“ç»“æ„"""
    # ğŸ—‘ï¸ åˆ é™¤è§¦å‘å™¨
    connection = op.get_bind()
    if connection.dialect.name == 'mysql':
        try:
            connection.execute(sa.text("DROP TRIGGER IF EXISTS update_user_points_timestamp"))
        except:
            pass
    
    # ğŸ—‘ï¸ åˆ é™¤ç´¢å¼•å’Œè¡¨
    op.drop_index('ix_user_points_points', table_name='user_points')
    op.drop_index('ix_user_points_user_id', table_name='user_points')
    op.drop_table('user_points')

# ğŸ› ï¸ è‡ªå®šä¹‰è¿ç§»å·¥å…·
class MigrationHelper:
    """è¿ç§»è¾…åŠ©å·¥å…·"""
    
    @staticmethod
    def safe_add_column(table_name, column_name, column_type, **kwargs):
        """å®‰å…¨æ·»åŠ åˆ—ï¼ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼‰"""
        connection = op.get_bind()
        inspector = sa.inspect(connection)
        columns = [col['name'] for col in inspector.get_columns(table_name)]
        
        if column_name not in columns:
            op.add_column(table_name, sa.Column(column_name, column_type, **kwargs))
            print(f"âœ… å·²æ·»åŠ åˆ—: {table_name}.{column_name}")
        else:
            print(f"âš ï¸  åˆ—å·²å­˜åœ¨: {table_name}.{column_name}")
    
    @staticmethod
    def safe_create_index(index_name, table_name, columns):
        """å®‰å…¨åˆ›å»ºç´¢å¼•"""
        try:
            op.create_index(index_name, table_name, columns)
            print(f"âœ… å·²åˆ›å»ºç´¢å¼•: {index_name}")
        except Exception as e:
            print(f"âš ï¸  ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_name} - {str(e)}")
    
    @staticmethod
    def batch_update_data(table_name, updates, batch_size=1000):
        """æ‰¹é‡æ›´æ–°æ•°æ®"""
        connection = op.get_bind()
        
        for update_sql in updates:
            try:
                result = connection.execute(sa.text(update_sql))
                print(f"âœ… æ‰¹é‡æ›´æ–°å®Œæˆ: å½±å“ {result.rowcount} è¡Œ")
            except Exception as e:
                print(f"âŒ æ›´æ–°å¤±è´¥: {str(e)}")
                raise
```

## ğŸ”— 6.6 è¿æ¥æ± ä¸äº‹åŠ¡ç®¡ç†

### è¿æ¥æ± ä¼˜åŒ–é…ç½®

```python
from sqlalchemy import create_engine, event
from sqlalchemy.pool import QueuePool, NullPool
import logging

class DatabaseManager:
    """ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, app=None):
        self.app = app
        self.engine = None
        
        if app is not None:
            self.init_app(app)
    
    def init_app(self, app):
        """åˆå§‹åŒ–æ•°æ®åº“é…ç½®"""
        # ğŸ”§ è¿æ¥æ± é…ç½®
        pool_config = {
            'poolclass': QueuePool,
            'pool_size': app.config.get('DB_POOL_SIZE', 10),
            'max_overflow': app.config.get('DB_MAX_OVERFLOW', 20),
            'pool_timeout': app.config.get('DB_POOL_TIMEOUT', 30),
            'pool_recycle': app.config.get('DB_POOL_RECYCLE', 3600),
            'pool_pre_ping': True,  # è¿æ¥å‰æ£€æŸ¥æœ‰æ•ˆæ€§
        }
        
        # ğŸ¯ æ ¹æ®ç¯å¢ƒè°ƒæ•´é…ç½®
        if app.config.get('TESTING'):
            pool_config.update({
                'poolclass': NullPool,  # æµ‹è¯•ç¯å¢ƒä¸ä½¿ç”¨è¿æ¥æ± 
                'pool_pre_ping': False,
            })
        
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = pool_config
        
        # ğŸ“Š è¿æ¥æ± ç›‘æ§
        self._setup_pool_monitoring()
    
    def _setup_pool_monitoring(self):
        """è®¾ç½®è¿æ¥æ± ç›‘æ§"""
        @event.listens_for(db.engine, 'connect')
        def on_connect(dbapi_connection, connection_record):
            app.logger.debug('æ•°æ®åº“è¿æ¥å·²å»ºç«‹')
        
        @event.listens_for(db.engine, 'checkout')
        def on_checkout(dbapi_connection, connection_record, connection_proxy):
            pool = db.engine.pool
            app.logger.debug(f'è¿æ¥æ± çŠ¶æ€: {pool.checkedout()}/{pool.size()}')
        
        @event.listens_for(db.engine, 'invalid')
        def on_invalid(dbapi_connection, connection_record, exception):
            app.logger.error(f'æ•°æ®åº“è¿æ¥æ— æ•ˆ: {exception}')

# ğŸ”„ äº‹åŠ¡ç®¡ç†å™¨
class TransactionManager:
    """äº‹åŠ¡ç®¡ç†å™¨"""
    
    @staticmethod
    @contextmanager
    def atomic_transaction():
        """åŸå­äº‹åŠ¡ä¸Šä¸‹æ–‡"""
        session = db.session
        try:
            session.begin()
            yield session
            session.commit()
            app.logger.debug('äº‹åŠ¡æäº¤æˆåŠŸ')
        except Exception as e:
            session.rollback()
            app.logger.error(f'äº‹åŠ¡å›æ»š: {str(e)}')
            raise
        finally:
            session.close()
    
    @staticmethod
    def retry_on_deadlock(max_retries=3, delay=0.1):
        """æ­»é”é‡è¯•è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                for attempt in range(max_retries):
                    try:
                        return func(*args, **kwargs)
                    except Exception as e:
                        if 'deadlock' in str(e).lower() and attempt < max_retries - 1:
                            time.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
                            continue
                        raise
                return None
            return wrapper
        return decorator

# ä½¿ç”¨ç¤ºä¾‹
@TransactionManager.retry_on_deadlock(max_retries=3)
def complex_business_operation():
    """å¤æ‚ä¸šåŠ¡æ“ä½œç¤ºä¾‹"""
    with TransactionManager.atomic_transaction() as session:
        # ä¸šåŠ¡é€»è¾‘
        user = session.query(User).get(1)
        user.points += 100
        
        # è®°å½•æ“ä½œæ—¥å¿—
        log = OperationLog(
            user_id=user.id,
            operation='add_points',
            details={'amount': 100}
        )
        session.add(log)
```

## ğŸŒ 6.7 NoSQL æ•°æ®åº“é›†æˆï¼ˆMongoDBã€Redisï¼‰

### MongoDB é›†æˆ

```python
from flask_pymongo import PyMongo
from bson import ObjectId
import json

class MongoManager:
    """ğŸƒ MongoDB ç®¡ç†å™¨"""
    
    def __init__(self, app=None):
        self.mongo = None
        if app:
            self.init_app(app)
    
    def init_app(self, app):
        """åˆå§‹åŒ–MongoDBè¿æ¥"""
        app.config['MONGO_URI'] = app.config.get(
            'MONGO_URI', 
            'mongodb://localhost:27017/flask_app'
        )
        self.mongo = PyMongo(app)
    
    def get_collection(self, name):
        """è·å–é›†åˆ"""
        return self.mongo.db[name]

# ğŸ“„ æ–‡æ¡£æ¨¡å‹ç±»
class DocumentModel:
    """MongoDBæ–‡æ¡£åŸºç±»"""
    
    def __init__(self, collection_name):
        self.collection = mongo_manager.get_collection(collection_name)
    
    def create(self, document):
        """åˆ›å»ºæ–‡æ¡£"""
        document['created_at'] = datetime.utcnow()
        document['updated_at'] = datetime.utcnow()
        result = self.collection.insert_one(document)
        return str(result.inserted_id)
    
    def find_by_id(self, doc_id):
        """æ ¹æ®IDæŸ¥æ‰¾æ–‡æ¡£"""
        return self.collection.find_one({'_id': ObjectId(doc_id)})
    
    def update(self, doc_id, updates):
        """æ›´æ–°æ–‡æ¡£"""
        updates['updated_at'] = datetime.utcnow()
        return self.collection.update_one(
            {'_id': ObjectId(doc_id)},
            {'$set': updates}
        )
    
    def delete(self, doc_id):
        """åˆ é™¤æ–‡æ¡£"""
        return self.collection.delete_one({'_id': ObjectId(doc_id)})

# ğŸ“Š å…·ä½“ä¸šåŠ¡æ¨¡å‹
class ArticleDocument(DocumentModel):
    """æ–‡ç« æ–‡æ¡£æ¨¡å‹"""
    
    def __init__(self):
        super().__init__('articles')
    
    def create_article(self, title, content, author_id, tags=None):
        """åˆ›å»ºæ–‡ç« """
        article = {
            'title': title,
            'content': content,
            'author_id': author_id,
            'tags': tags or [],
            'views': 0,
            'likes': 0,
            'status': 'draft'
        }
        return self.create(article)
    
    def search_articles(self, keyword, limit=10):
        """å…¨æ–‡æœç´¢æ–‡ç« """
        return list(self.collection.find(
            {'$text': {'$search': keyword}},
            {'score': {'$meta': 'textScore'}}
        ).sort([('score', {'$meta': 'textScore'})]).limit(limit))
    
    def get_popular_articles(self, limit=10):
        """è·å–çƒ­é—¨æ–‡ç« """
        return list(self.collection.find(
            {'status': 'published'}
        ).sort('views', -1).limit(limit))

# åˆ›å»ºå…¨æ–‡ç´¢å¼•
def create_text_index():
    """åˆ›å»ºæ–‡æœ¬æœç´¢ç´¢å¼•"""
    articles = mongo_manager.get_collection('articles')
    articles.create_index([
        ('title', 'text'),
        ('content', 'text'),
        ('tags', 'text')
    ])
```

### Redis é›†æˆä¸ç¼“å­˜ç­–ç•¥

```python
import redis
import pickle
import json
from functools import wraps

class RedisManager:
    """ğŸ”´ Redis ç®¡ç†å™¨"""
    
    def __init__(self, app=None):
        self.redis_client = None
        if app:
            self.init_app(app)
    
    def init_app(self, app):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        redis_config = {
            'host': app.config.get('REDIS_HOST', 'localhost'),
            'port': app.config.get('REDIS_PORT', 6379),
            'db': app.config.get('REDIS_DB', 0),
            'password': app.config.get('REDIS_PASSWORD'),
            'decode_responses': True,
            'socket_timeout': 5,
            'socket_connect_timeout': 5,
            'retry_on_timeout': True,
        }
        
        self.redis_client = redis.Redis(**redis_config)
        
        # æµ‹è¯•è¿æ¥
        try:
            self.redis_client.ping()
            app.logger.info('Redisè¿æ¥æˆåŠŸ')
        except redis.ConnectionError:
            app.logger.error('Redisè¿æ¥å¤±è´¥')
    
    def get(self, key):
        """è·å–ç¼“å­˜"""
        try:
            value = self.redis_client.get(key)
            return json.loads(value) if value else None
        except (json.JSONDecodeError, redis.RedisError):
            return None
    
    def set(self, key, value, expire=3600):
        """è®¾ç½®ç¼“å­˜"""
        try:
            return self.redis_client.setex(
                key, 
                expire, 
                json.dumps(value, default=str)
            )
        except redis.RedisError:
            return False
    
    def delete(self, key):
        """åˆ é™¤ç¼“å­˜"""
        try:
            return self.redis_client.delete(key)
        except redis.RedisError:
            return False

# ğŸ¯ ç¼“å­˜è£…é¥°å™¨
def cache_result(expire=3600, key_prefix=''):
    """ç»“æœç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{key_prefix}:{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = redis_manager.get(cache_key)
            if cached_result is not None:
                app.logger.debug(f'ç¼“å­˜å‘½ä¸­: {cache_key}')
                return cached_result
            
            # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
            result = func(*args, **kwargs)
            redis_manager.set(cache_key, result, expire)
            app.logger.debug(f'ç¼“å­˜è®¾ç½®: {cache_key}')
            
            return result
        return wrapper
    return decorator

# ğŸ“Š ç¼“å­˜æœåŠ¡ç±»
class CacheService:
    """ç¼“å­˜æœåŠ¡"""
    
    @staticmethod
    @cache_result(expire=1800, key_prefix='posts')
    def get_popular_posts(limit=10):
        """è·å–çƒ­é—¨æ–‡ç« ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        return PostService.get_posts_with_stats()[:limit]
    
    @staticmethod
    def invalidate_user_cache(user_id):
        """æ¸…é™¤ç”¨æˆ·ç›¸å…³ç¼“å­˜"""
        patterns = [
            f'user:{user_id}:*',
            f'posts:user:{user_id}:*',
            f'timeline:{user_id}:*'
        ]
        
        for pattern in patterns:
            keys = redis_manager.redis_client.keys(pattern)
            if keys:
                redis_manager.redis_client.delete(*keys)
    
    @staticmethod
    def get_user_session(session_id):
        """è·å–ç”¨æˆ·ä¼šè¯"""
        return redis_manager.get(f'session:{session_id}')
    
    @staticmethod
    def set_user_session(session_id, user_data, expire=86400):
        """è®¾ç½®ç”¨æˆ·ä¼šè¯"""
        return redis_manager.set(f'session:{session_id}', user_data, expire)
```

### ğŸ”„ æ··åˆæ•°æ®åº“æ¶æ„

```mermaid
flowchart TB
    subgraph "åº”ç”¨å±‚"
        A[Flaskåº”ç”¨] --> B[æ•°æ®è®¿é—®å±‚]
    end
    
    subgraph "æ•°æ®è®¿é—®å±‚"
        B --> C[å…³ç³»å‹æ•°æ®åº“]
        B --> D[æ–‡æ¡£æ•°æ®åº“]
        B --> E[ç¼“å­˜å±‚]
    end
    
    subgraph "å­˜å‚¨å±‚"
        C --> F[(PostgreSQL)]
        C --> G[(MySQL)]
        D --> H[(MongoDB)]
        E --> I[(Redis)]
    end
    
    subgraph "æ•°æ®ç±»å‹"
        J[ç»“æ„åŒ–æ•°æ®] --> F
        K[åŠç»“æ„åŒ–æ•°æ®] --> H
        L[ä¸´æ—¶æ•°æ®] --> I
        M[ä¼šè¯æ•°æ®] --> I
    end
```

### ğŸ“Š æ•°æ®åº“æ€§èƒ½ç›‘æ§

```python
class DatabaseMonitor:
    """ğŸ“Š æ•°æ®åº“æ€§èƒ½ç›‘æ§"""
    
    @staticmethod
    def log_slow_queries():
        """è®°å½•æ…¢æŸ¥è¯¢"""
        @event.listens_for(db.engine, 'before_cursor_execute')
        def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            context._query_start_time = time.time()
        
        @event.listens_for(db.engine, 'after_cursor_execute')
        def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            total = time.time() - context._query_start_time
            if total > 1.0:  # è¶…è¿‡1ç§’çš„æŸ¥è¯¢
                app.logger.warning(f'æ…¢æŸ¥è¯¢: {total:.2f}s - {statement[:100]}...')
    
    @staticmethod
    def get_connection_pool_status():
        """è·å–è¿æ¥æ± çŠ¶æ€"""
        pool = db.engine.pool
        return {
            'pool_size': pool.size(),
            'checked_out': pool.checkedout(),
            'overflow': pool.overflow(),
            'checked_in': pool.checkedin()
        }
    
    @staticmethod
    def get_redis_info():
        """è·å–Redisä¿¡æ¯"""
        try:
            info = redis_manager.redis_client.info()
            return {
                'connected_clients': info.get('connected_clients'),
                'used_memory_human': info.get('used_memory_human'),
                'keyspace_hits': info.get('keyspace_hits'),
                'keyspace_misses': info.get('keyspace_misses')
            }
        except redis.RedisError:
            return None
```

## ğŸ¯ æœ€ä½³å®è·µæ€»ç»“

```mermaid
mindmap
  root((æ•°æ®åº“æœ€ä½³å®è·µ))
    è®¾è®¡åŸåˆ™
      è§„èŒƒåŒ–è®¾è®¡
      ç´¢å¼•ä¼˜åŒ–
      å…³ç³»æ˜ å°„
      æ•°æ®å®Œæ•´æ€§
    æ€§èƒ½ä¼˜åŒ–
      æŸ¥è¯¢ä¼˜åŒ–
      è¿æ¥æ± ç®¡ç†
      ç¼“å­˜ç­–ç•¥
      ç›‘æ§å‘Šè­¦
    è¿ç»´ç®¡ç†
      æ•°æ®åº“è¿ç§»
      å¤‡ä»½æ¢å¤
      ç‰ˆæœ¬æ§åˆ¶
      ç¯å¢ƒéš”ç¦»
    å®‰å…¨é˜²æŠ¤
      SQLæ³¨å…¥é˜²æŠ¤
      è®¿é—®æ§åˆ¶
      æ•°æ®åŠ å¯†
      å®¡è®¡æ—¥å¿—
```

### ğŸ¯ æ ¸å¿ƒè¦ç‚¹

1. **ğŸ—ï¸ åˆç†è®¾è®¡**ï¼šéµå¾ªæ•°æ®åº“è®¾è®¡èŒƒå¼ï¼Œå»ºç«‹æ¸…æ™°çš„å…³ç³»æ˜ å°„
2. **âš¡ æ€§èƒ½ä¼˜å…ˆ**ï¼šåˆç†ä½¿ç”¨ç´¢å¼•ï¼Œä¼˜åŒ–æŸ¥è¯¢è¯­å¥ï¼Œé¿å…N+1é—®é¢˜
3. **ğŸ”„ æ¸è¿›è¿ç§»**ï¼šä½¿ç”¨ç‰ˆæœ¬åŒ–è¿ç§»ï¼Œç¡®ä¿æ•°æ®åº“ç»“æ„å˜æ›´çš„å¯æ§æ€§
4. **ğŸŒ æ··åˆæ¶æ„**ï¼šæ ¹æ®æ•°æ®ç‰¹æ€§é€‰æ‹©åˆé€‚çš„å­˜å‚¨æ–¹æ¡ˆ
5. **ğŸ“Š æŒç»­ç›‘æ§**ï¼šå»ºç«‹å®Œå–„çš„æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶

é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†Flaskæ•°æ®åº“å¼€å‘çš„æ ¸å¿ƒæŠ€æœ¯å’Œæœ€ä½³å®è·µã€‚è¿™äº›çŸ¥è¯†å°†å¸®åŠ©ä½ æ„å»ºé«˜æ€§èƒ½ã€å¯æ‰©å±•çš„æ•°æ®é©±åŠ¨åº”ç”¨ã€‚
        